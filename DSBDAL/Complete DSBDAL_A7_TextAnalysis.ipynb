{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP2lf3nM6/u5E6SbJbJkWlR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tfs_h7hnZqTC","executionInfo":{"status":"ok","timestamp":1713031091709,"user_tz":-330,"elapsed":4078,"user":{"displayName":"Vivek Gotecha","userId":"00337109865623423029"}},"outputId":"c0fcde89-70fd-4644-d21a-18ff9e09d215"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Package abc is already up-to-date!\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Package alpino is already up-to-date!\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n","[nltk_data]    |       to-date!\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n","[nltk_data]    |       up-to-date!\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package basque_grammars is already up-to-date!\n","[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n","[nltk_data]    |   Package bcp47 is already up-to-date!\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package book_grammars is already up-to-date!\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Package brown is already up-to-date!\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Package brown_tei is already up-to-date!\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Package cess_cat is already up-to-date!\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Package cess_esp is already up-to-date!\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Package chat80 is already up-to-date!\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package city_database is already up-to-date!\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Package cmudict is already up-to-date!\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package comparative_sentences is already up-to-\n","[nltk_data]    |       date!\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    |   Package comtrans is already up-to-date!\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Package conll2000 is already up-to-date!\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Package conll2002 is already up-to-date!\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    |   Package conll2007 is already up-to-date!\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Package crubadan is already up-to-date!\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package dependency_treebank is already up-to-date!\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Package dolch is already up-to-date!\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package europarl_raw is already up-to-date!\n","[nltk_data]    | Downloading package extended_omw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package extended_omw is already up-to-date!\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Package floresta is already up-to-date!\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package framenet_v15 is already up-to-date!\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package framenet_v17 is already up-to-date!\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Package gazetteers is already up-to-date!\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Package genesis is already up-to-date!\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Package gutenberg is already up-to-date!\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Package ieer is already up-to-date!\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Package inaugural is already up-to-date!\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Package indian is already up-to-date!\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    |   Package jeita is already up-to-date!\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Package kimmo is already up-to-date!\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    |   Package knbc is already up-to-date!\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package large_grammars is already up-to-date!\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Package mac_morpho is already up-to-date!\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    |   Package machado is already up-to-date!\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    |   Package masc_tagged is already up-to-date!\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n","[nltk_data]    |       to-date!\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package moses_sample is already up-to-date!\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package movie_reviews is already up-to-date!\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Package mte_teip5 is already up-to-date!\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Package names is already up-to-date!\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Package nps_chat is already up-to-date!\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    |   Package omw is already up-to-date!\n","[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]    |   Package omw-1.4 is already up-to-date!\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Package paradigms is already up-to-date!\n","[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n","[nltk_data]    |   Package pe08 is already up-to-date!\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package perluniprops is already up-to-date!\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Package pil is already up-to-date!\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Package pl196x is already up-to-date!\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Package porter_test is already up-to-date!\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Package ppattach is already up-to-date!\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package problem_reports is already up-to-date!\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    |   Package propbank is already up-to-date!\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Package pros_cons is already up-to-date!\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Package ptb is already up-to-date!\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Package punkt is already up-to-date!\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Package qc is already up-to-date!\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    |   Package reuters is already up-to-date!\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Package rslp is already up-to-date!\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Package rte is already up-to-date!\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package sample_grammars is already up-to-date!\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    |   Package semcor is already up-to-date!\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Package senseval is already up-to-date!\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package sentence_polarity is already up-to-date!\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package sentiwordnet is already up-to-date!\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Package shakespeare is already up-to-date!\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package sinica_treebank is already up-to-date!\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Package smultron is already up-to-date!\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package snowball_data is already up-to-date!\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package spanish_grammars is already up-to-date!\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Package state_union is already up-to-date!\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Package stopwords is already up-to-date!\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package subjectivity is already up-to-date!\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Package swadesh is already up-to-date!\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Package switchboard is already up-to-date!\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Package tagsets is already up-to-date!\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Package timit is already up-to-date!\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Package toolbox is already up-to-date!\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Package treebank is already up-to-date!\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package twitter_samples is already up-to-date!\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Package udhr is already up-to-date!\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Package udhr2 is already up-to-date!\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package unicode_samples is already up-to-date!\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package universal_tagset is already up-to-date!\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n","[nltk_data]    |       date!\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package vader_lexicon is already up-to-date!\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Package verbnet is already up-to-date!\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Package verbnet3 is already up-to-date!\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Package webtext is already up-to-date!\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Package wmt15_eval is already up-to-date!\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package word2vec_sample is already up-to-date!\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    |   Package wordnet is already up-to-date!\n","[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n","[nltk_data]    |   Package wordnet2021 is already up-to-date!\n","[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n","[nltk_data]    |   Package wordnet2022 is already up-to-date!\n","[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n","[nltk_data]    |   Package wordnet31 is already up-to-date!\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Package wordnet_ic is already up-to-date!\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Package words is already up-to-date!\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Package ycoe is already up-to-date!\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["import nltk\n","nltk.download('all')"]},{"cell_type":"code","source":["import string\n","import math\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"metadata":{"id":"KD27KmFQft6p","executionInfo":{"status":"ok","timestamp":1713031091709,"user_tz":-330,"elapsed":21,"user":{"displayName":"Vivek Gotecha","userId":"00337109865623423029"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["with open('document.txt', 'r') as file:\n","  text = file.read()\n","\n","print(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5JnaR_Zbiba","executionInfo":{"status":"ok","timestamp":1713031091710,"user_tz":-330,"elapsed":21,"user":{"displayName":"Vivek Gotecha","userId":"00337109865623423029"}},"outputId":"9d602ca4-26b8-4584-b67a-1101021c5411"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["The cat sat on the mat.\n","The dog ran after the cat.\n","The bird flew in the sky.\n"]}]},{"cell_type":"code","source":["# 1) tokenization (In-built are nltk.word_tokenize())\n","def tokenize(text):\n","  words = text.split()\n","  tokens = []\n","  for word in words:\n","    word = word.translate(str.maketrans('', '', string.punctuation))\n","    if word:\n","      tokens.append(word.lower())\n","  return tokens\n","\n","\n","word_tokens = tokenize(text)\n","print(word_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8PXc65A3atzX","executionInfo":{"status":"ok","timestamp":1713031091710,"user_tz":-330,"elapsed":16,"user":{"displayName":"Vivek Gotecha","userId":"00337109865623423029"}},"outputId":"2f915f9b-d203-401e-b236-3c06953508bb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['the', 'cat', 'sat', 'on', 'the', 'mat', 'the', 'dog', 'ran', 'after', 'the', 'cat', 'the', 'bird', 'flew', 'in', 'the', 'sky']\n"]}]},{"cell_type":"code","source":["# 2) POS Tag\n","print(\"Parts of speech : \", nltk.pos_tag(word_tokens))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIhu9nEDeguO","executionInfo":{"status":"ok","timestamp":1713031091710,"user_tz":-330,"elapsed":14,"user":{"displayName":"Vivek Gotecha","userId":"00337109865623423029"}},"outputId":"f7dbdfca-94d1-4fb0-968f-42d29985486d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Parts of speech :  [('the', 'DT'), ('cat', 'NN'), ('sat', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('the', 'DT'), ('dog', 'NN'), ('ran', 'VBD'), ('after', 'IN'), ('the', 'DT'), ('cat', 'NN'), ('the', 'DT'), ('bird', 'NN'), ('flew', 'VBD'), ('in', 'IN'), ('the', 'DT'), ('sky', 'NN')]\n"]}]},{"cell_type":"code","source":["# 3 Stop Words Removal\n","stop_words = nltk.corpus.stopwords.words('english')\n","\n","def remove_stopWords(tokens, sw):\n","  filtered_tokens = [word for word in tokens if word not in sw]\n","  return filtered_tokens\n","\n","filtered_tokens = remove_stopWords(word_tokens, stop_words)\n","print(filtered_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVMyVLnZg6jp","executionInfo":{"status":"ok","timestamp":1713031091710,"user_tz":-330,"elapsed":12,"user":{"displayName":"Vivek Gotecha","userId":"00337109865623423029"}},"outputId":"0cefcf2a-51f0-43ad-b122-cb1574b153dd"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['cat', 'sat', 'mat', 'dog', 'ran', 'cat', 'bird', 'flew', 'sky']\n"]}]},{"cell_type":"code","source":["# 4) Stemming\n","ps = nltk.PorterStemmer()\n","\n","def apply_stemming(tokens):\n","  stemmed_tokens = [ps.stem(word) for word in tokens]\n","  return stemmed_tokens\n","\n","stemmed_tokens = apply_stemming(filtered_tokens)\n","print(stemmed_tokens)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9kYSXOTYcZOt","executionInfo":{"status":"ok","timestamp":1713031091710,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vivek Gotecha","userId":"00337109865623423029"}},"outputId":"a8744052-ab88-43de-d946-85c54bcf5135"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['cat', 'sat', 'mat', 'dog', 'ran', 'cat', 'bird', 'flew', 'sky']\n"]}]},{"cell_type":"code","source":["# 5 Lemmatization\n","lemmatizer = nltk.WordNetLemmatizer()\n","\n","def apply_lemmatization(tokens):\n","  lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","  return lemmatized_tokens\n","\n","lemmatized_tokens = apply_lemmatization(filtered_tokens)\n","print(lemmatized_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nc2UNxvgiZho","executionInfo":{"status":"ok","timestamp":1713031093782,"user_tz":-330,"elapsed":2075,"user":{"displayName":"Vivek Gotecha","userId":"00337109865623423029"}},"outputId":"6a6da62e-0faf-4949-ee68-dcc1b2d2ddb6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['cat', 'sat', 'mat', 'dog', 'ran', 'cat', 'bird', 'flew', 'sky']\n"]}]},{"cell_type":"code","source":["# 6) Calculate TF\n","tf = {}\n","total_terms = len(lemmatized_tokens)\n","for term in lemmatized_tokens:\n","  tf[term] = tf.get(term, 0) + 1\n","\n","tf_normalized = {term: freq / total_terms for term, freq in tf.items()}\n","\n","# 7) Calculate IDF\n","document_frequency = {}\n","for term in set(lemmatized_tokens):\n","  document_frequency[term] = sum(1 for doc_tokens in [lemmatized_tokens] if term in doc_tokens)\n","\n","idf = {term : math.log10(len([lemmatized_tokens]) / df) for term, df in document_frequency.items()}\n","\n","tfidf = {term : tf_normalized[term] * idf[term] for term in tf_normalized}\n","\n","for term in tfidf:\n","  print(f\"{term}: TF = {tf_normalized[term]}, IDF = {idf[term]}, TF-IDF = {tfidf[term]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qKre17rGjfjD","executionInfo":{"status":"ok","timestamp":1713031093783,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vivek Gotecha","userId":"00337109865623423029"}},"outputId":"efaa0c39-4db0-4269-d6b3-9a592b0be69f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["cat: TF = 0.2222222222222222, IDF = 0.0, TF-IDF = 0.0\n","sat: TF = 0.1111111111111111, IDF = 0.0, TF-IDF = 0.0\n","mat: TF = 0.1111111111111111, IDF = 0.0, TF-IDF = 0.0\n","dog: TF = 0.1111111111111111, IDF = 0.0, TF-IDF = 0.0\n","ran: TF = 0.1111111111111111, IDF = 0.0, TF-IDF = 0.0\n","bird: TF = 0.1111111111111111, IDF = 0.0, TF-IDF = 0.0\n","flew: TF = 0.1111111111111111, IDF = 0.0, TF-IDF = 0.0\n","sky: TF = 0.1111111111111111, IDF = 0.0, TF-IDF = 0.0\n"]}]}]}